{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "## Introduction\n",
    "\n",
    "You've now learned about many different ways to create features to model more complex relationships. If you included interaction terms between all of your variables and high order polynomial functions, you will no doubt have an issue with overfitting to noise. In this lesson, you'll learn about the different techniques you can use to only use features that are most relevant to your model.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* List the different methods of feature selection\n",
    "* Identify when it is appropriate to use certain methods of feature selection\n",
    "* Use feature selection on a dataset\n",
    "\n",
    "### Purpose of Feature Selection\n",
    "\n",
    "Feature selection is the process by which you select a subset of features relevant for model construction. Feature Selection comes with several benefits, the most obvious being the improvement of a machine learning algorithm. Other benefits include:\n",
    "\n",
    "* Decrease in computational complexity: As the number of features are reduced in a model, the easier it will be to compute the parameters of your model. It will also mean a decrease in the amount of data storage required to maintain the features of your model.\n",
    "* Understanding your data: In the process of feature selection, you will gain more of an understanding of how features relate to one another.\n",
    "\n",
    "Now, let's look at the different types of feature selection and their advantages/disadvantages.\n",
    "\n",
    "### Types of Feature Selection\n",
    "\n",
    "Like many things in data science there is not a clear and easy answer for deciding what features to include in a model. There are however, different strategies you can use to process in the correct manner.\n",
    "\n",
    "\n",
    "* Domain Knowledge\n",
    "* Wrapper Methods\n",
    "* Filter Methods\n",
    "* Embedded Methods\n",
    "\n",
    "\n",
    "#### Domain Knowledge   \n",
    "One of the first steps a data scientist should take when trying to determine what types of features might be useful is knowledge of the specific domain related to your dataset. This might mean reading past research papers that have explored similar topics or asking to key stakeholders to determine what the believe the most important factors are for predicting something.\n",
    "\n",
    "\n",
    "#### Wrapper Methods   \n",
    "Wrapper methods determine the optimal subset of features using different combinations of features to train models and then calculating performance. Every subset is used to train models and then evaluated on a test test. As you might imagine, wrapper methods can end up being very computationally intensive, however they are highly effective in determining the optimal subset. Because wrapper methods are so time-consuming, it becomes challenging to use them with large feature sets. \n",
    "\n",
    "<img src = \"./images/wrapper.png\">\n",
    "\n",
    "An example of a wrapper method in linear regression is Recursive Feature Elimination, which starts with all features included in a model and removes them one by one. After the model has had a feature removed, whichever subset of features resulted in the least statistically significant deterioration of the model fit will indicate which omitted feature is the least useful for prediction. The opposite of this process is Forward Selection, which undergoes the same process in reverse. It begins with a single feature and continues to add the next feature that improves model performance the most. \n",
    "\n",
    "Let's see a wrapper method in action on the diabetes dataset built into scikit-learn. The dataset contains the independent variables age, sex, body mass index, blood pressure, and 6 different blood serum measurements. The target variable represents a quantitative measurement progression of diabetes from one year after a baseline observation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter Methods   \n",
    "Filter methods are feature selection methods carried out as a pre-processing step before even running a model. Filter methods work by observing characteristics of how variables are related to one another. Depending on the model that is being used, different metrics are used to determine which features will get eliminated and which will remain. Typically, filter methods will return a \"feature ranking\" that will tell you how features are ordered in relation to one another. They will remove the variables that are considered redundant. It's up to the data scientist to determine the cut-off point at which they will keep the top n features, and this n is usually determined through cross validation.\n",
    "\n",
    "<img src= \"./images/filter.png\">\n",
    "\n",
    "In the linear regression context, a common filter method is to eliminate features that are two highly correlated with one another. Another method is to use a variance threshold. This sets some threshold of required variance for features in order to include them in a model. The though process behind this is that if variables do not have a high variance, they will not change much and will therefore not have much impact on our dependent variable.\n",
    "\n",
    "\n",
    "#### Embedded methods   \n",
    "Embedded methods are feature selection methods that are included within the actual formulation of your machine learning algorithm. The most common kind of embedded method is regularization, in particular Lasso, because it has the capability of reducing your set of features automatically.\n",
    "\n",
    "<img src = \"./images/embedded.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BP</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "      <th>S5</th>\n",
       "      <th>S6</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>32.1</td>\n",
       "      <td>101.0</td>\n",
       "      <td>157</td>\n",
       "      <td>93.2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.8598</td>\n",
       "      <td>87</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>21.6</td>\n",
       "      <td>87.0</td>\n",
       "      <td>183</td>\n",
       "      <td>103.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8918</td>\n",
       "      <td>69</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>30.5</td>\n",
       "      <td>93.0</td>\n",
       "      <td>156</td>\n",
       "      <td>93.6</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.6728</td>\n",
       "      <td>85</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>25.3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>198</td>\n",
       "      <td>131.4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.8903</td>\n",
       "      <td>89</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>192</td>\n",
       "      <td>125.4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.2905</td>\n",
       "      <td>80</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE  SEX   BMI     BP   S1     S2    S3   S4      S5  S6    Y\n",
       "0   59    2  32.1  101.0  157   93.2  38.0  4.0  4.8598  87  151\n",
       "1   48    1  21.6   87.0  183  103.2  70.0  3.0  3.8918  69   75\n",
       "2   72    2  30.5   93.0  156   93.6  41.0  4.0  4.6728  85  141\n",
       "3   24    1  25.3   84.0  198  131.4  40.0  5.0  4.8903  89  206\n",
       "4   50    1  23.0  101.0  192  125.4  52.0  4.0  4.2905  80  135"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# reading in the diabetes dataset built into sklearn\n",
    "df = pd.read_csv('diabetes.tab.txt', sep='\\t', lineterminator='\\n')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BP</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "      <th>S5</th>\n",
       "      <th>S6</th>\n",
       "      <th>female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>32.1</td>\n",
       "      <td>101.0</td>\n",
       "      <td>157</td>\n",
       "      <td>93.2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.8598</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>21.6</td>\n",
       "      <td>87.0</td>\n",
       "      <td>183</td>\n",
       "      <td>103.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8918</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>30.5</td>\n",
       "      <td>93.0</td>\n",
       "      <td>156</td>\n",
       "      <td>93.6</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.6728</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>25.3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>198</td>\n",
       "      <td>131.4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.8903</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>23.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>192</td>\n",
       "      <td>125.4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.2905</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE   BMI     BP   S1     S2    S3   S4      S5  S6  female\n",
       "0   59  32.1  101.0  157   93.2  38.0  4.0  4.8598  87       1\n",
       "1   48  21.6   87.0  183  103.2  70.0  3.0  3.8918  69       0\n",
       "2   72  30.5   93.0  156   93.6  41.0  4.0  4.6728  85       1\n",
       "3   24  25.3   84.0  198  131.4  40.0  5.0  4.8903  89       0\n",
       "4   50  23.0  101.0  192  125.4  52.0  4.0  4.2905  80       0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtaining the X and Y variables from the dataframe\n",
    "features = df.iloc[:,:-1]\n",
    "target = df['Y']\n",
    "# creating dummy variable for sex\n",
    "features['female'] = pd.get_dummies(features['SEX'],drop_first=True)\n",
    "features.drop(columns=['SEX'], inplace=True)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    151\n",
       "1     75\n",
       "2    141\n",
       "3    206\n",
       "4    135\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=20,test_size=0.2)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "## scaling every feature except the binary column female\n",
    "scaler.fit(X_train.iloc[:,:-1])\n",
    "transformed_training_features = scaler.transform(X_train.iloc[:,:-1])\n",
    "transformed_testing_features = scaler.transform(X_test.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = np.column_stack((transformed_training_features,X_train['female']))\n",
    "X_test_transformed = np.column_stack((transformed_testing_features,X_test['female']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BP</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "      <th>S5</th>\n",
       "      <th>S6</th>\n",
       "      <th>female</th>\n",
       "      <th>...</th>\n",
       "      <th>S5^3</th>\n",
       "      <th>S5^2 S6</th>\n",
       "      <th>S5^2 female</th>\n",
       "      <th>S5 S6^2</th>\n",
       "      <th>S5 S6 female</th>\n",
       "      <th>S5 female^2</th>\n",
       "      <th>S6^3</th>\n",
       "      <th>S6^2 female</th>\n",
       "      <th>S6 female^2</th>\n",
       "      <th>female^3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.433522</td>\n",
       "      <td>-0.967597</td>\n",
       "      <td>-2.067847</td>\n",
       "      <td>-1.623215</td>\n",
       "      <td>-1.280312</td>\n",
       "      <td>-0.347527</td>\n",
       "      <td>-0.852832</td>\n",
       "      <td>-1.095555</td>\n",
       "      <td>-1.006077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.314929</td>\n",
       "      <td>-1.207535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.108911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-1.018343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.117754</td>\n",
       "      <td>-0.516691</td>\n",
       "      <td>1.142458</td>\n",
       "      <td>-0.168101</td>\n",
       "      <td>-0.129601</td>\n",
       "      <td>-0.424950</td>\n",
       "      <td>-0.083651</td>\n",
       "      <td>0.543382</td>\n",
       "      <td>-0.831901</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160442</td>\n",
       "      <td>-0.245631</td>\n",
       "      <td>0.295264</td>\n",
       "      <td>0.376053</td>\n",
       "      <td>-0.452040</td>\n",
       "      <td>0.543382</td>\n",
       "      <td>-0.575725</td>\n",
       "      <td>0.692060</td>\n",
       "      <td>-0.831901</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.350445</td>\n",
       "      <td>1.850570</td>\n",
       "      <td>1.427819</td>\n",
       "      <td>0.413945</td>\n",
       "      <td>0.764667</td>\n",
       "      <td>-1.044334</td>\n",
       "      <td>1.454710</td>\n",
       "      <td>0.597504</td>\n",
       "      <td>1.519478</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213315</td>\n",
       "      <td>0.542470</td>\n",
       "      <td>0.357011</td>\n",
       "      <td>1.379524</td>\n",
       "      <td>0.907894</td>\n",
       "      <td>0.597504</td>\n",
       "      <td>3.508190</td>\n",
       "      <td>2.308813</td>\n",
       "      <td>1.519478</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.511086</td>\n",
       "      <td>-1.373413</td>\n",
       "      <td>-1.711146</td>\n",
       "      <td>-0.837453</td>\n",
       "      <td>-1.148802</td>\n",
       "      <td>1.278358</td>\n",
       "      <td>-1.622013</td>\n",
       "      <td>-0.796071</td>\n",
       "      <td>-0.918989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.504494</td>\n",
       "      <td>-0.582390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.672315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.776124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.743778</td>\n",
       "      <td>0.114579</td>\n",
       "      <td>-0.141664</td>\n",
       "      <td>-1.565010</td>\n",
       "      <td>-1.339491</td>\n",
       "      <td>-0.115257</td>\n",
       "      <td>-0.852832</td>\n",
       "      <td>-0.970101</td>\n",
       "      <td>0.648597</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.912957</td>\n",
       "      <td>0.610391</td>\n",
       "      <td>0.941095</td>\n",
       "      <td>-0.408100</td>\n",
       "      <td>-0.629204</td>\n",
       "      <td>-0.970101</td>\n",
       "      <td>0.272850</td>\n",
       "      <td>0.420678</td>\n",
       "      <td>0.648597</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AGE       BMI        BP        S1        S2        S3        S4  \\\n",
       "0 -0.433522 -0.967597 -2.067847 -1.623215 -1.280312 -0.347527 -0.852832   \n",
       "1  1.117754 -0.516691  1.142458 -0.168101 -0.129601 -0.424950 -0.083651   \n",
       "2  1.350445  1.850570  1.427819  0.413945  0.764667 -1.044334  1.454710   \n",
       "3 -0.511086 -1.373413 -1.711146 -0.837453 -1.148802  1.278358 -1.622013   \n",
       "4 -0.743778  0.114579 -0.141664 -1.565010 -1.339491 -0.115257 -0.852832   \n",
       "\n",
       "         S5        S6  female    ...         S5^3   S5^2 S6  S5^2 female  \\\n",
       "0 -1.095555 -1.006077     0.0    ...    -1.314929 -1.207535     0.000000   \n",
       "1  0.543382 -0.831901     1.0    ...     0.160442 -0.245631     0.295264   \n",
       "2  0.597504  1.519478     1.0    ...     0.213315  0.542470     0.357011   \n",
       "3 -0.796071 -0.918989     0.0    ...    -0.504494 -0.582390     0.000000   \n",
       "4 -0.970101  0.648597     1.0    ...    -0.912957  0.610391     0.941095   \n",
       "\n",
       "    S5 S6^2  S5 S6 female  S5 female^2      S6^3  S6^2 female  S6 female^2  \\\n",
       "0 -1.108911      0.000000    -0.000000 -1.018343     0.000000    -0.000000   \n",
       "1  0.376053     -0.452040     0.543382 -0.575725     0.692060    -0.831901   \n",
       "2  1.379524      0.907894     0.597504  3.508190     2.308813     1.519478   \n",
       "3 -0.672315      0.000000    -0.000000 -0.776124     0.000000    -0.000000   \n",
       "4 -0.408100     -0.629204    -0.970101  0.272850     0.420678     0.648597   \n",
       "\n",
       "   female^3  \n",
       "0       0.0  \n",
       "1       1.0  \n",
       "2       1.0  \n",
       "3       0.0  \n",
       "4       1.0  \n",
       "\n",
       "[5 rows x 285 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = preprocessing.PolynomialFeatures(degree=3, interaction_only=False, include_bias=False)\n",
    "features_64_train = pd.DataFrame(poly.fit_transform(X_train_transformed), columns=poly.get_feature_names(features.columns))\n",
    "features_64_test = pd.DataFrame(poly.transform(X_test_transformed), columns=poly.get_feature_names(features.columns))\n",
    "features_64_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter Methods  \n",
    "Let's begin by trying out some filter methods for feature selection. The benefit of filter methods is that they can provide us with some useful visualizations for helping us gain an understanding about characteristics of our data. To begin with, let's use a simple variance threshold to eliminate those features with a low variance.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarianceThreshold(threshold=1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "selector = VarianceThreshold(threshold = 1)\n",
    "selector.fit(features_64_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many features that eliminated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Item wrong length 285 instead of 353.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-76f7b08d104e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfeatures_64_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2677\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2678\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2679\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2680\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2681\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2714\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2715\u001b[0m                 raise ValueError('Item wrong length %d instead of %d.' %\n\u001b[0;32m-> 2716\u001b[0;31m                                  (len(key), len(self.index)))\n\u001b[0m\u001b[1;32m   2717\u001b[0m             \u001b[0;31m# check_bool_indexer will throw exception if Series key cannot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2718\u001b[0m             \u001b[0;31m# be reindexed to match DataFrame rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Item wrong length 285 instead of 353."
     ]
    }
   ],
   "source": [
    "print(np.sum(selector.get_support()))\n",
    "features_64_train[selector.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_64_train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wrapper Methods\n",
    "\n",
    "Now let's use RFE to try out a wrapper method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFE(estimator=LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False),\n",
       "  n_features_to_select=15, step=1, verbose=0)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "rfe = RFE(lm,n_features_to_select=15)\n",
    "rfe.fit(features_64_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4371729585878992"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.score(features_64_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources: [Feature Selection](https://www.researchgate.net/profile/Amparo_Alonso-Betanzos/publication/221252792_Filter_Methods_for_Feature_Selection_-_A_Comparative_Study/links/543fd9ec0cf21227a11b8e05.pdf)\n",
    "\n",
    "\n",
    "[An Introduction to Variable and Feature Selection](http://www.jmlr.org/papers/volume3/guyon03a/guyon03a.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This lesson formalized the different types of feature selection and introduced some new techniques to you. In the next lab, you'll get a chance to test out these feature selection methods to make the optimal model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
